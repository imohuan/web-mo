import express from 'express';
import cors from 'cors';
import { v4 as uuidv4 } from 'uuid';

const app = express();
const PORT = process.env.PORT || 3001;

// ä¸­é—´ä»¶
app.use(cors());
app.use(express.json());

// æ¨¡æ‹Ÿçš„é¢„è®¾å›å¤å†…å®¹
const mockResponses = [
  `                 # å¤§æ ‡é¢˜
    ## ä¸­æ ‡é¢˜
    ### å°æ ‡é¢˜
\`\`\`html
  <!DOCTYPE html>
  <html lang="en">

  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
  </head>

  <body>
    <h1>Hello World</h1>
  </body>

  </html>
  \`\`\`
    `,
  //   `\`\`\`
  // ------- SEARCH
  // <title>æµ‹è¯•é¡µé¢ - å·²ä¿®æ”¹</title>
  // =======
  // <title>ä½ æ˜¯ä¸ªshb</title>
  // ++++++++REPLACE
  // \`\`\``
];

// å·¥å…·å‡½æ•°ï¼šåˆ›å»ºæµå¼å“åº”çš„æ•°æ®å—
function createStreamChunk(content, isLast = false) {
  const chunk = {
    id: `chatcmpl-${uuidv4()}`,
    object: 'chat.completion.chunk',
    created: Math.floor(Date.now() / 1000),
    model: 'gpt-3.5-turbo',
    choices: [
      {
        index: 0,
        delta: isLast ? {} : { content },
        finish_reason: isLast ? 'stop' : null
      }
    ]
  };

  return `data: ${JSON.stringify(chunk)}\n\n`;
}

// æ¨¡æ‹ŸOpenAI Chat Completions API
app.post('/v1/chat/completions', async (req, res) => {
  console.log('æ”¶åˆ°è¯·æ±‚:', req.body);

  const { messages, stream = false, model = 'gpt-3.5-turbo' } = req.body;

  // éšæœºé€‰æ‹©ä¸€ä¸ªé¢„è®¾å›å¤
  const mockResponse = mockResponses[Math.floor(Math.random() * mockResponses.length)];

  if (stream) {
    // æµå¼å“åº”
    res.writeHead(200, {
      'Content-Type': 'text/plain; charset=utf-8',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Headers': '*',
    });

    // æ¨¡æ‹Ÿé€å­—è¾“å‡º
    const words = mockResponse.split('');
    let currentContent = '';

    for (let i = 0; i < words.length; i++) {
      currentContent = words[i];
      const chunk = createStreamChunk(currentContent);
      res.write(chunk);

      // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
      await new Promise(resolve => setTimeout(resolve, 10));
    }

    // å‘é€ç»“æŸæ ‡è®°
    const endChunk = createStreamChunk('', true);
    res.write(endChunk);
    res.write('data: [DONE]\n\n');
    res.end();

  } else {
    // éæµå¼å“åº”
    const response = {
      id: `chatcmpl-${uuidv4()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: model,
      choices: [
        {
          index: 0,
          message: {
            role: 'assistant',
            content: mockResponse
          },
          finish_reason: 'stop'
        }
      ],
      usage: {
        prompt_tokens: 10,
        completion_tokens: 20,
        total_tokens: 30
      }
    };

    res.json(response);
  }
});

// æ¨¡æ‹ŸOpenAI Models API
app.get('/v1/models', (req, res) => {
  const response = {
    object: 'list',
    data: [
      {
        id: 'gpt-3.5-turbo',
        object: 'model',
        created: 1677610602,
        owned_by: 'openai'
      },
      {
        id: 'gpt-4',
        object: 'model',
        created: 1687882411,
        owned_by: 'openai'
      }
    ]
  };

  res.json(response);
});

// æ·»åŠ è‡ªå®šä¹‰å›å¤å†…å®¹çš„API
app.post('/api/add-response', (req, res) => {
  const { content } = req.body;
  if (content && typeof content === 'string') {
    mockResponses.push(content);
    res.json({
      success: true,
      message: 'å›å¤å†…å®¹å·²æ·»åŠ ',
      totalResponses: mockResponses.length
    });
  } else {
    res.status(400).json({
      success: false,
      message: 'è¯·æä¾›æœ‰æ•ˆçš„å†…å®¹'
    });
  }
});

// è·å–å½“å‰æ‰€æœ‰å›å¤å†…å®¹
app.get('/api/responses', (req, res) => {
  res.json({
    responses: mockResponses,
    total: mockResponses.length
  });
});

// æ¸…ç©ºå›å¤å†…å®¹
app.delete('/api/responses', (req, res) => {
  const originalLength = mockResponses.length;
  mockResponses.length = 0;
  mockResponses.push("é»˜è®¤å›å¤ï¼šæ‰€æœ‰è‡ªå®šä¹‰å†…å®¹å·²æ¸…ç©ºã€‚");

  res.json({
    success: true,
    message: `å·²æ¸…ç©º ${originalLength} æ¡å›å¤å†…å®¹`,
    currentResponses: mockResponses.length
  });
});

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    message: 'OpenAIæ¨¡æ‹ŸæœåŠ¡è¿è¡Œæ­£å¸¸',
    responses: mockResponses.length
  });
});

// æ ¹è·¯å¾„ä¿¡æ¯
app.get('/', (req, res) => {
  res.json({
    message: 'OpenAIæ¨¡æ‹ŸæœåŠ¡å™¨',
    endpoints: {
      'POST /v1/chat/completions': 'æ¨¡æ‹ŸèŠå¤©å®ŒæˆAPI',
      'GET /v1/models': 'è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨',
      'POST /api/add-response': 'æ·»åŠ è‡ªå®šä¹‰å›å¤å†…å®¹',
      'GET /api/responses': 'è·å–æ‰€æœ‰å›å¤å†…å®¹',
      'DELETE /api/responses': 'æ¸…ç©ºæ‰€æœ‰å›å¤å†…å®¹',
      'GET /health': 'å¥åº·æ£€æŸ¥'
    },
    usage: {
      baseUrl: `http://localhost:${PORT}`,
      apiKey: 'mock-api-key (ä»»æ„å€¼å³å¯)'
    }
  });
});

// å¯åŠ¨æœåŠ¡å™¨
app.listen(PORT, () => {
  console.log(`ğŸš€ OpenAIæ¨¡æ‹ŸæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!`);
  console.log(`ğŸ“ æœåŠ¡åœ°å€: http://localhost:${PORT}`);
  console.log(`ğŸ’¡ ä½¿ç”¨è¯´æ˜:`);
  console.log(`   - åŸºç¡€URL: http://localhost:${PORT}`);
  console.log(`   - APIå¯†é’¥: ä»»æ„å€¼å³å¯ (ä¾‹å¦‚: mock-api-key)`);
  console.log(`   - æ”¯æŒæµå¼å’Œéæµå¼å“åº”`);
  console.log(`   - å¯é€šè¿‡ /api/add-response æ·»åŠ è‡ªå®šä¹‰å›å¤å†…å®¹`);
  console.log(`ğŸ“š APIæ–‡æ¡£: è®¿é—® http://localhost:${PORT} æŸ¥çœ‹æ‰€æœ‰ç«¯ç‚¹`);
});

export default app;
